{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic-Supervised-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevChorong/Supervised-Learning/blob/master/Basic_Supervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dapaYZwilpuO",
        "colab_type": "text"
      },
      "source": [
        "# Basic Supervised Learning\n",
        "******\n",
        "This Note is for 'Basic Level Supervised Learning'\n",
        "\n",
        "we just know about the grammer that some of scikit-learn that include about Decision-Tree\n",
        "\n",
        "## [1] Decision Tree \n",
        "\n",
        "### # INDEX\n",
        "> 1. Call Scikit-learn\n",
        "> 2. Make some Training Dataset / Test Dataset\n",
        "> 3. gatering **Features** and **Labels**\n",
        "> 4. Training the **Classifier** several time to enough \n",
        "> 5. Predict the Test Dataset\n",
        "> 6. Make Confidence ratio\n",
        "> 7. Visualize the DecisionTree\n",
        "\n",
        "\n",
        "### # 1. Call Scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk5VIuI8sEfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree # Call Decision Tree from Scikit-Learn lib ( call it sklearn ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A4d0jC3s6Pn",
        "colab_type": "text"
      },
      "source": [
        "### # 2. Make some Training Dataset / Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_dabQKBs_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahmr8-UvbJw",
        "colab_type": "text"
      },
      "source": [
        "### # 3. gatering **Features** and **Labels**\n",
        "before we gatering Features and Labels\n",
        "we just know about what kinds of Features that dataset has"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjrq5wyrvvbj",
        "colab_type": "code",
        "outputId": "46b3ed25-a5fb-4625-e32e-e8c0c442059e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(\"Features : {0}\".format(iris_data['feature_names']))\n",
        "\n",
        "print(\"First data : {0}\".format(iris_data['data'][:1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features : ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "First data : [[5.1 3.5 1.4 0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pc_T9AfwkxY",
        "colab_type": "text"
      },
      "source": [
        "that we know about what kinds of Features that dataset has\n",
        "> 1. sepal length (cm)\n",
        "> 2. sepal width (cm)\n",
        "> 3. petal length (cm)\n",
        "> 4. petal width (cm)\n",
        "\n",
        "so in first Data we can decode that data like this\n",
        "\n",
        "**\"[1] : Sepal length 5.1cm, Sepal width 3.5cm, Petal length 1.4cm, Petal width 0.2cm\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifkoh9PaxzFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = train  # 'feature' would be 'train'\n",
        "labels = A_train  # 'answer(Label)' is would be 'A_train'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRy7aBtBxvY0",
        "colab_type": "text"
      },
      "source": [
        "### # 4. Training the **Classifier** several time to enough "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-bego3iyaKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = train  # 'feature' would be 'train'\n",
        "labels = A_train  # 'answer(Label)' is would be 'A_train'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnKi972ozGx6",
        "colab_type": "text"
      },
      "source": [
        "### # 5. Predict the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrp-vYhSzHB6",
        "colab_type": "code",
        "outputId": "294c989e-a1b8-4f54-bab4-5d05351f4823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = train  # 'feature' would be 'train'\n",
        "labels = A_train  # 'answer(Label)' is would be 'A_train'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)\n",
        "\n",
        "#========[ 5 ]=========================#\n",
        "perdict = clf.predict(test) # checking between two answer\n",
        "print(perdict)\n",
        "print(A_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0]\n",
            "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PxG_tD2Y7H",
        "colab_type": "text"
      },
      "source": [
        "### # 6. Make Confidence ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "82ffed7a-4e7d-4519-f287-f4109fe1c996",
        "id": "gJ9WJoHW3H-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = train  # 'feature' would be 'train'\n",
        "labels = A_train  # 'answer(Label)' is would be 'A_train'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)\n",
        "\n",
        "#========[ 5 ]=========================#\n",
        "perdict = clf.predict(test) # checking between two answer\n",
        "\n",
        "#========[ 6 ]=========================#\n",
        "token = 0;\n",
        "\n",
        "for i in range(len(A_test)):    # if it is collect give token +1\n",
        "  if(perdict[i] == A_test[i]):\n",
        "    token += 1;\n",
        "    \n",
        "confidence = token / len(A_test)\n",
        "print(confidence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVD_nOLljaLZ",
        "colab_type": "text"
      },
      "source": [
        "### # 7. Visualize the DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAGpzgbvjiB1",
        "colab_type": "code",
        "outputId": "0aaf36f2-d119-4355-c006-5cf97b0181fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.model_selection import train_test_split # this function make Training and test data randomly\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train, test, A_train, A_test = train_test_split(iris_data['data'], iris_data['target'], random_state = 1)\n",
        "\n",
        "# train = Training Data\n",
        "# A_train = Training Data Answer Label\n",
        "# test = test Data\n",
        "# A_test = test Data Answer Label\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = train  # 'feature' would be 'train'\n",
        "labels = A_train  # 'answer(Label)' is would be 'A_train'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)\n",
        "\n",
        "#========[ 5 ]=========================#\n",
        "perdict = clf.predict(test) # checking between two answer\n",
        "\n",
        "#========[ 6 ]=========================#\n",
        "token = 0;\n",
        "\n",
        "for i in range(len(A_test)):    # if it is collect give token +1\n",
        "  if(perdict[i] == A_test[i]):\n",
        "    token += 1;\n",
        "    \n",
        "confidence = token / len(A_test)\n",
        "print(confidence)\n",
        "\n",
        "#========[ 7 ]=========================#\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True,special_characters=True) # in First Parameter we should in Classifier\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "\n",
        "\n",
        "# Image(graph.create_png()) # if you want to see the result in Jupyter-Notebook or Google-colab you should erase pound Key(#) front of this code"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}